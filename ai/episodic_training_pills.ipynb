{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQLsAJC01D5m",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train a model with Episodic Training\n",
    "Episodic training has attracted a lot of interest in the early years of Few-Shot Learning research. Some papers still use it, and refer to it as \"meta-learning\".\n",
    "\n",
    "Recent works distinguish the Few-Shot Classifier from the training framework, so as from v1.0 of EasyFSL, methods to episodically train a classifier were taken out of the logic of the FewShotClassifier class. Instead, we provide in this notebook an example of how to perform episodic training on a few-shot classifier.\n",
    "\n",
    "Use it, copy it, change it, get crazy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5aFVwdT1D5t",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Getting started\n",
    "First we're going to do some imports (this is not the interesting part)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "A1LKM7vX1D5v",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "from statistics import mean\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkgsfhkD1D5z"
   },
   "source": [
    "Then we're gonna do the most important thing in Machine Learning research: ensuring reproducibility by setting the random seed. We're going to set the seed for all random packages that we could possibly use, plus some other stuff to make CUDA deterministic (see [here](https://pytorch.org/docs/stable/notes/randomness.html)).\n",
    "\n",
    "I strongly encourage that you do this in **all your scripts**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ocLk4O-G1D50",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtQokWas1D51"
   },
   "source": [
    "Then we're gonna set the shape of our problem.\n",
    "\n",
    "Also we define our set-up, like the device (change it if you don't have CUDA) or the number of workers for data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "_0rB2h7C1D52",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_way = 5\n",
    "n_shot = 3\n",
    "n_query = 10\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "n_workers = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyfsl.datasets import EasySet\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "PILLS_SPECS_DIR = Path(\"data/pills\")\n",
    "\n",
    "\n",
    "class Pills(EasySet):\n",
    "    def __init__(self, split: str, **kwargs):\n",
    "        \n",
    "        # specs_file = PILLS_SPECS_DIR / f\"{split}.json\"\n",
    "        specs_file = f\"training/{split}.json\"\n",
    "\n",
    "        super().__init__(specs_file=specs_file, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1T7446uT1D54",
    "outputId": "0de2ffe7-fb9a-405a-d73f-8d802f6e7313",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of labels in the dataset (0 must be greater or equal to n_way (5).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training_pills.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training_pills.ipynb#X42sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m val_set \u001b[39m=\u001b[39m Pills(split\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training_pills.ipynb#X42sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Those are special batch samplers that sample few-shot classification tasks with a pre-defined shape\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training_pills.ipynb#X42sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m train_sampler \u001b[39m=\u001b[39m TaskSampler(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training_pills.ipynb#X42sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     train_set, n_way\u001b[39m=\u001b[39;49mn_way, n_shot\u001b[39m=\u001b[39;49mn_shot, n_query\u001b[39m=\u001b[39;49mn_query, n_tasks\u001b[39m=\u001b[39;49mn_tasks_per_epoch\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training_pills.ipynb#X42sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training_pills.ipynb#X42sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m val_sampler \u001b[39m=\u001b[39m TaskSampler(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training_pills.ipynb#X42sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     val_set, n_way\u001b[39m=\u001b[39mn_way, n_shot\u001b[39m=\u001b[39mn_shot, n_query\u001b[39m=\u001b[39mn_query, n_tasks\u001b[39m=\u001b[39mn_validation_tasks\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training_pills.ipynb#X42sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training_pills.ipynb#X42sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Finally, the DataLoader. We customize the collate_fn so that batches are delivered\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training_pills.ipynb#X42sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# in the shape: (support_images, support_labels, query_images, query_labels, class_ids)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/pillpicker/ai/.env/lib/python3.11/site-packages/easyfsl/samplers/task_sampler.py:52\u001b[0m, in \u001b[0;36mTaskSampler.__init__\u001b[0;34m(self, dataset, n_way, n_shot, n_query, n_tasks)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems_per_label[label] \u001b[39m=\u001b[39m [item]\n\u001b[0;32m---> 52\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_dataset_size_fits_sampler_parameters()\n",
      "File \u001b[0;32m~/Documents/GitHub/pillpicker/ai/.env/lib/python3.11/site-packages/easyfsl/samplers/task_sampler.py:172\u001b[0m, in \u001b[0;36mTaskSampler._check_dataset_size_fits_sampler_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_dataset_size_fits_sampler_parameters\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    169\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39m    Check that the dataset size is compatible with the sampler parameters\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_dataset_has_enough_labels()\n\u001b[1;32m    173\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_dataset_has_enough_items_per_label()\n",
      "File \u001b[0;32m~/Documents/GitHub/pillpicker/ai/.env/lib/python3.11/site-packages/easyfsl/samplers/task_sampler.py:177\u001b[0m, in \u001b[0;36mTaskSampler._check_dataset_has_enough_labels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_dataset_has_enough_labels\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    176\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_way \u001b[39m>\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems_per_label):\n\u001b[0;32m--> 177\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    178\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe number of labels in the dataset (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems_per_label)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    179\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmust be greater or equal to n_way (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_way\u001b[39m}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The number of labels in the dataset (0 must be greater or equal to n_way (5)."
     ]
    }
   ],
   "source": [
    "from easyfsl.samplers import TaskSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "n_tasks_per_epoch = 500\n",
    "n_validation_tasks = 100\n",
    "\n",
    "# Instantiate the datasets\n",
    "train_set =Pills(split=\"train\", training=True)\n",
    "val_set = Pills(split=\"val\", training=False)\n",
    "\n",
    "# Those are special batch samplers that sample few-shot classification tasks with a pre-defined shape\n",
    "train_sampler = TaskSampler(\n",
    "    train_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_tasks_per_epoch\n",
    ")\n",
    "val_sampler = TaskSampler(\n",
    "    val_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_validation_tasks\n",
    ")\n",
    "\n",
    "# Finally, the DataLoader. We customize the collate_fn so that batches are delivered\n",
    "# in the shape: (support_images, support_labels, query_images, query_labels, class_ids)\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_sampler=train_sampler,\n",
    "    num_workers=n_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=train_sampler.episodic_collate_fn,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_sampler=val_sampler,\n",
    "    num_workers=n_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=val_sampler.episodic_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfX-JEEd1D55"
   },
   "source": [
    "And then we define the network. Here I chose Prototypical Networks and the built-in ResNet18 from PyTorch because it's easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7gW9FSUf1D55",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from easyfsl.methods import PrototypicalNetworks, FewShotClassifier\n",
    "from easyfsl.modules import resnet12\n",
    "\n",
    "\n",
    "convolutional_network = resnet12()\n",
    "few_shot_classifier = PrototypicalNetworks(convolutional_network).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KaDd3CVm1D56"
   },
   "source": [
    "Now let's define our training helpers ! I chose to use Stochastic Gradient Descent on 200 epochs with a scheduler that divides the learning rate by 10 after 120 and 160 epochs. The strategy is derived from [this repo](https://github.com/fiveai/on-episodes-fsl).\n",
    "\n",
    "We're also gonna use a TensorBoard because it's always good to see what your training curves look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "d2EZR3yA1D56",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import SGD, Optimizer\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "LOSS_FUNCTION = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 200\n",
    "scheduler_milestones = [120, 160]\n",
    "scheduler_gamma = 0.1\n",
    "learning_rate = 1e-2\n",
    "tb_logs_dir = Path(\".\")\n",
    "\n",
    "train_optimizer = SGD(\n",
    "    few_shot_classifier.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4\n",
    ")\n",
    "train_scheduler = MultiStepLR(\n",
    "    train_optimizer,\n",
    "    milestones=scheduler_milestones,\n",
    "    gamma=scheduler_gamma,\n",
    ")\n",
    "\n",
    "tb_writer = SummaryWriter(log_dir=str(tb_logs_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTgldYnI1D57"
   },
   "source": [
    "And now let's get to it! Here we define the function that performs a training epoch.\n",
    "\n",
    "We use tqdm to monitor the training in real time in our logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "fyLOQ2A21D58",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def training_epoch(\n",
    "    model: FewShotClassifier, data_loader: DataLoader, optimizer: Optimizer\n",
    "):\n",
    "    all_loss = []\n",
    "    model.train()\n",
    "    with tqdm(\n",
    "        enumerate(data_loader), total=len(data_loader), desc=\"Training\"\n",
    "    ) as tqdm_train:\n",
    "        for episode_index, (\n",
    "            support_images,\n",
    "            support_labels,\n",
    "            query_images,\n",
    "            query_labels,\n",
    "            _,\n",
    "        ) in tqdm_train:\n",
    "            optimizer.zero_grad()\n",
    "            model.process_support_set(\n",
    "                support_images.to(DEVICE), support_labels.to(DEVICE)\n",
    "            )\n",
    "            classification_scores = model(query_images.to(DEVICE))\n",
    "\n",
    "            loss = LOSS_FUNCTION(classification_scores, query_labels.to(DEVICE))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            all_loss.append(loss.item())\n",
    "\n",
    "            tqdm_train.set_postfix(loss=mean(all_loss))\n",
    "\n",
    "    return mean(all_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMyYb6pB1D58"
   },
   "source": [
    "And we have everything we need! To perform validations we'll just use the built-in `evaluate` function from `easyfsl.methods.utils`.\n",
    "\n",
    "This is now the time to **start training**.\n",
    "\n",
    "I added something to log the state of the model that gave the best performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 500/500 [05:47<00:00,  1.44it/s, loss=1.51]\n",
      "Validation: 100%|██████████| 100/100 [01:18<00:00,  1.28it/s, accuracy=0.466]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   9%|▊         | 43/500 [00:24<04:19,  1.76it/s, loss=1.41]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training.ipynb Cell 20\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epochs):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     average_loss \u001b[39m=\u001b[39m training_epoch(few_shot_classifier, train_loader, train_optimizer)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training.ipynb#X25sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     validation_accuracy \u001b[39m=\u001b[39m evaluate(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         few_shot_classifier, val_loader, device\u001b[39m=\u001b[39mDEVICE, tqdm_prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mValidation\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training.ipynb#X25sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training.ipynb#X25sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mif\u001b[39;00m validation_accuracy \u001b[39m>\u001b[39m best_validation_accuracy:\n",
      "\u001b[1;32m/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training.ipynb#X25sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m episode_index, (\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     support_images,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training.ipynb#X25sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     support_labels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training.ipynb#X25sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     _,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training.ipynb#X25sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m ) \u001b[39min\u001b[39;00m tqdm_train:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training.ipynb#X25sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training.ipynb#X25sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     model\u001b[39m.\u001b[39;49mprocess_support_set(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training.ipynb#X25sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         support_images\u001b[39m.\u001b[39;49mto(DEVICE), support_labels\u001b[39m.\u001b[39;49mto(DEVICE)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training.ipynb#X25sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training.ipynb#X25sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     classification_scores \u001b[39m=\u001b[39m model(query_images\u001b[39m.\u001b[39mto(DEVICE))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benswerdlow/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/notebooks/episodic_training.ipynb#X25sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     loss \u001b[39m=\u001b[39m LOSS_FUNCTION(classification_scores, query_labels\u001b[39m.\u001b[39mto(DEVICE))\n",
      "File \u001b[0;32m~/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/easyfsl/methods/few_shot_classifier.py:77\u001b[0m, in \u001b[0;36mFewShotClassifier.process_support_set\u001b[0;34m(self, support_images, support_labels)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_support_set\u001b[39m(\n\u001b[1;32m     66\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     67\u001b[0m     support_images: Tensor,\n\u001b[1;32m     68\u001b[0m     support_labels: Tensor,\n\u001b[1;32m     69\u001b[0m ):\n\u001b[1;32m     70\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    Harness information from the support set, so that query labels can later be predicted using a forward call.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39m    The default behaviour shared by most few-shot classifiers is to compute prototypes and store the support set.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39m        support_labels: labels of support set images of shape (n_support, )\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_prototypes_and_store_support_set(support_images, support_labels)\n",
      "File \u001b[0;32m~/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/easyfsl/methods/few_shot_classifier.py:150\u001b[0m, in \u001b[0;36mFewShotClassifier.compute_prototypes_and_store_support_set\u001b[0;34m(self, support_images, support_labels)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_features(support_images)\n\u001b[1;32m    149\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_error_if_features_are_multi_dimensional(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_features)\n\u001b[0;32m--> 150\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprototypes \u001b[39m=\u001b[39m compute_prototypes(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msupport_features, support_labels)\n",
      "File \u001b[0;32m~/Documents/GitHub/pillpicker/ai/easy-few-shot-learning/easyfsl/methods/utils.py:18\u001b[0m, in \u001b[0;36mcompute_prototypes\u001b[0;34m(support_features, support_labels)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_prototypes\u001b[39m(support_features: Tensor, support_labels: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m      8\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m    Compute class prototypes from support features and labels\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m        for each label of the support set, the average feature vector of instances with this label\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     n_way \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(torch\u001b[39m.\u001b[39;49munique(support_labels))\n\u001b[1;32m     19\u001b[0m     \u001b[39m# Prototype i is the mean of all instances of features corresponding to labels == i\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(\n\u001b[1;32m     21\u001b[0m         [\n\u001b[1;32m     22\u001b[0m             support_features[torch\u001b[39m.\u001b[39mnonzero(support_labels \u001b[39m==\u001b[39m label)]\u001b[39m.\u001b[39mmean(\u001b[39m0\u001b[39m)\n\u001b[1;32m     23\u001b[0m             \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_way)\n\u001b[1;32m     24\u001b[0m         ]\n\u001b[1;32m     25\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GitHub/pillpicker/ai/.env/lib/python3.11/site-packages/torch/_jit_internal.py:488\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[39mreturn\u001b[39;00m if_true(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    487\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 488\u001b[0m     \u001b[39mreturn\u001b[39;00m if_false(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/GitHub/pillpicker/ai/.env/lib/python3.11/site-packages/torch/_jit_internal.py:488\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[39mreturn\u001b[39;00m if_true(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    487\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 488\u001b[0m     \u001b[39mreturn\u001b[39;00m if_false(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/GitHub/pillpicker/ai/.env/lib/python3.11/site-packages/torch/functional.py:976\u001b[0m, in \u001b[0;36m_return_output\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39minput\u001b[39m):\n\u001b[1;32m    974\u001b[0m     \u001b[39mreturn\u001b[39;00m _unique_impl(\u001b[39minput\u001b[39m, \u001b[39msorted\u001b[39m, return_inverse, return_counts, dim)\n\u001b[0;32m--> 976\u001b[0m output, _, _ \u001b[39m=\u001b[39m _unique_impl(\u001b[39minput\u001b[39;49m, \u001b[39msorted\u001b[39;49m, return_inverse, return_counts, dim)\n\u001b[1;32m    977\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/Documents/GitHub/pillpicker/ai/.env/lib/python3.11/site-packages/torch/functional.py:890\u001b[0m, in \u001b[0;36m_unique_impl\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    882\u001b[0m     output, inverse_indices, counts \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39munique_dim(\n\u001b[1;32m    883\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m    884\u001b[0m         dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m         return_counts\u001b[39m=\u001b[39mreturn_counts,\n\u001b[1;32m    888\u001b[0m     )\n\u001b[1;32m    889\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 890\u001b[0m     output, inverse_indices, counts \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_unique2(\n\u001b[1;32m    891\u001b[0m         \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    892\u001b[0m         \u001b[39msorted\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39msorted\u001b[39;49m,\n\u001b[1;32m    893\u001b[0m         return_inverse\u001b[39m=\u001b[39;49mreturn_inverse,\n\u001b[1;32m    894\u001b[0m         return_counts\u001b[39m=\u001b[39;49mreturn_counts,\n\u001b[1;32m    895\u001b[0m     )\n\u001b[1;32m    896\u001b[0m \u001b[39mreturn\u001b[39;00m output, inverse_indices, counts\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from easyfsl.utils import evaluate\n",
    "\n",
    "\n",
    "best_state = few_shot_classifier.state_dict()\n",
    "best_validation_accuracy = 0.0\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    average_loss = training_epoch(few_shot_classifier, train_loader, train_optimizer)\n",
    "    validation_accuracy = evaluate(\n",
    "        few_shot_classifier, val_loader, device=DEVICE, tqdm_prefix=\"Validation\"\n",
    "    )\n",
    "\n",
    "    if validation_accuracy > best_validation_accuracy:\n",
    "        best_validation_accuracy = validation_accuracy\n",
    "        best_state = few_shot_classifier.state_dict()\n",
    "        print(\"Ding ding ding! We found a new best model!\")\n",
    "    \n",
    "    if epoch % 15 == 0:\n",
    "        torch.save(best_state, f\"best_model_{epoch}.pt\")\n",
    "    \n",
    "    tb_writer.add_scalar(\"Train/loss\", average_loss, epoch)\n",
    "    tb_writer.add_scalar(\"Val/acc\", validation_accuracy, epoch)\n",
    "\n",
    "    # Warn the scheduler that we did an epoch\n",
    "    # so it knows when to decrease the learning rate\n",
    "    train_scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Yay we successfully performed Episodic Training! Now if you want to you can retrieve the best model's state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "few_shot_classifier.load_state_dict(best_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Now that our model is trained, we want to test it.\n",
    "\n",
    "First step: we fetch the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_test_tasks = 1000\n",
    "\n",
    "test_set = CUB(split=\"test\", training=False)\n",
    "test_sampler = TaskSampler(\n",
    "    test_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_test_tasks\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_sampler=test_sampler,\n",
    "    num_workers=n_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=test_sampler.episodic_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Second step: we run the few-shot classifier on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = evaluate(few_shot_classifier, test_loader, device=DEVICE)\n",
    "print(f\"Average accuracy : {(100 * accuracy):.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Congrats! You performed Episodic Training using EasyFSL. If you want to compare with a model trained using classical training, look at [this other example notebook](classical_training.ipynb).\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "episodic_training.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
